<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 测试分享 | 怪兽说]]></title>
  <link href="http://yingl.github.io/blog/categories/ce-shi-fen-xiang/atom.xml" rel="self"/>
  <link href="http://yingl.github.io/"/>
  <updated>2014-08-04T17:12:40+08:00</updated>
  <id>http://yingl.github.io/</id>
  <author>
    <name><![CDATA[窥基／无柳无酒／黑灯瞎火]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[James Bach的Rapid Test培训总结]]></title>
    <link href="http://yingl.github.io/blog/2014/07/31/james-bach-rapid-test/"/>
    <updated>2014-07-31T20:41:01+08:00</updated>
    <id>http://yingl.github.io/blog/2014/07/31/james-bach-rapid-test</id>
    <content type="html"><![CDATA[<p>首先感谢阿里巴巴邀请James大神在北京办公室组织了Rapid Test的培训。本来报名的目的只是想和兄弟部门的同事找机会一起交流交流，对测试本身并没有抱太大的期望。结果课程开始之后，只能说不服不行。另外，哥活生生的被大神当作了教学道具&hellip;</p>

<p>虽然James大神脱离项目一线专注培训很多年了，而且也没有互联网项目经验，但是一上来就抓住了问题的本质，项目需求不清楚，进度紧张，资源有限，这都是当年项目情况活生生的写照啊！所谓的Rapid Test就是针对这些问题的。为什么这里不说敏捷Agile？因为这里只谈测试，而且谈的是普遍真理，不管你用Agile还是瀑布流，测试都必须解决的一些共性问题。</p>

<p>培训过程就不具体描述了，这里就谈几点总结：</p>

<ol>
<li>如何挖掘需求。在阿里测试人员经常听到开发人员说：这个功能做好了，你测一下，明天就发了。呃&hellip;好像这个到底是个什么样的功能都没搞清楚。所以对于测试人员要先了解这个系统，它的功能和设计目标。在教学中举了一个真实的例子，系统看着很简单，输入->判断->输出。一开始觉得这个系统简单，但是在得知是针对航天工程设计的系统时，实时性和稳定性就成为了重要的测试需求。在了解了输入系统的复杂程度之后，测试的重点也立刻明确了。所以对于测试人员，一边要自己摸索，同时也要和团队的其它成员密切沟通，获取需要的各种信息帮助决策。</li>
<li>关于测试用例。James基本上否定了测试用例的价值，这点和我们团队内部正在摸索的实践类似。从项目实践的角度来说，光凭借测试用例，我们无法1）评估测试的有效性；2）保持测试用例和实际情况同步（谁不服自己上Kelude看）；3）从测试用例无法了解整个系统（测试评审基本是在过流水）。大神的观点是基于场景做测试，你可以不写测试用例，但是不代表你不需要做你的家庭作业。取代测试用例的是如下的报告：1）测试场景；2）每个场景需要覆盖的功能点；3）对于每个功能点如何测试；4）场景设计的理由；5）重点测试模块的选择等。总儿言之，你必须让项目组成员相信你的测试是完整的，有足够覆盖的，能保证产品质量的。</li>
<li>探索性测试不是无目的的。探索意味着自由，自由意味着责任。因为你能负责，所以才给你一定的自由。你必须通过试探，分析，验证这个流程去深入了解产品，之后再去系统的分析，有针对性的设计测试，这样才是真正的探索性测试。探索不是漫无目的的随机布朗运动，而是要通过探索建立对整个产品的了解。</li>
<li>为什么课程叫Rapid而不是Agile敏捷？因为Rapid Test讲的是普遍真理，不管你用什么开发模式，敏捷或者传统的瀑布流都能解决问题。其实说到底，就是在人手有限，时间有限的情况下找到一个最好的平衡点，既能按时交付，又能保证质量。</li>
<li>测试人员的定位是守门员，是守住产品质量底线的人。这个观点不是很赞同，毕竟当代足球守门员还担负有后场防守组织的责任。个人认为当代软件测试还承担有带领团队保证软件质量以及不断改进质量的责任。</li>
<li>测试的第一要素是人，工具只是辅助。当人们在谈自动化测试的时候，有人要求过开发自动化编程吗？但是事实上，自动化编程某种程度上确实在发生，比如编译器的工作。对于自动化，我们的衡量标准是生产效率的提高和投入产出比。这个是值得我们在日常工作中借鉴的，有时候比起高大上的全自动化测试脚本，手工测试辅助工具更能提高效率，而且维护成本更低，投入产出比更高。</li>
</ol>


<p>课程只有短短两天，要是指望培训后能力有个突飞猛进那是没可能的。这个课程让你回到测试的原点，解答了为什么要做软件测试，如何做软件测试，如何像一个测试工程师一样思考问题，如何去发现问题。把这些原则与你工作实践想结合，才能真正的提高软件产品质量。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[38电影抢票活动测试分享]]></title>
    <link href="http://yingl.github.io/blog/2014/03/30/38-movie-falsh-sale/"/>
    <updated>2014-03-30T21:01:15+08:00</updated>
    <id>http://yingl.github.io/blog/2014/03/30/38-movie-falsh-sale</id>
    <content type="html"><![CDATA[<p>4月12日拔丝活动（buzz.cn）在上海有一场关于移动测试交流的活动，我会分享淘宝手机生活节测试的一些心得和经验。在这里先分享我直接负责的38电影抢票活动的总结。</p>

<!--more-->


<h3>项目时间点</h3>

<table>
<thead>
<tr>
<th></th>
<th align="left"><em>日期</em></th>
<th align="left"><em>事件</em></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="left">1/25 &ndash; 1/27 </td>
<td align="left">测试人员投入，开始编写测试用例，准备数据。</td>
</tr>
<tr>
<td></td>
<td align="left">1/28 </td>
<td align="left">冒烟测试完成</td>
</tr>
<tr>
<td></td>
<td align="left">2/12 &ndash; 2/11 </td>
<td align="left">日常环境测试完成</td>
</tr>
<tr>
<td></td>
<td align="left">2/12 &ndash; 3/1 </td>
<td align="left">1. 预发环境功能测试<br>2. 性能测试<br>3. 影院现场测试<br>4. 影院排期数据生成</td>
</tr>
<tr>
<td></td>
<td align="left">3/2 </td>
<td align="left">活动预热页面上线</td>
</tr>
<tr>
<td></td>
<td align="left">3/5 </td>
<td align="left">抢票活动开始，晚上有新需求大改版</td>
</tr>
<tr>
<td></td>
<td align="left">3/6 </td>
<td align="left">下午新版页面上线</td>
</tr>
<tr>
<td></td>
<td align="left">3/9 </td>
<td align="left">活动顺利结束</td>
</tr>
</tbody>
</table>


<p>虽然测因为其它项目的原因晚两天投入项目，但整个项目基本还是按照计划的时间节点前进，虽然预热页面上线时间晚了一天，但主要是线下影院无法准确提供3/8当天的准确排期。</p>

<h3>活动型项目的特点</h3>

<ol>
<li>短平快。整个项目扣除春节长假和额外休假，实际施工时间仅为1个月。包含了从需求分析、设计评审到开发测试整个流程。</li>
<li>投入资源有限。活动只投入一个后端、一个前端和一个测试。</li>
<li>一次性代码多。很多代码针对活动的特殊场景做了特殊的逻辑和硬编码处理，基本不考虑重用性。</li>
<li>测试链路长，上下游组件依赖关系复杂。</li>
<li>非技术因素影响复杂。必须对线下数据进行清洗。而且活动分线上线下部分，线下部分有很多不可控风险因素需要考虑。</li>
<li>及时响应前线反馈。</li>
</ol>


<h3>测试经验分享</h3>

<ol>
<li>Web UI自动化测试这种高大上东西基本就不考虑了。等这套东西能稳定跑起来活动都结束了，放到下次活动又是另一套玩法了。</li>
<li>测试模块化。由于测试链路长，依赖组件多，等各组件联调完成再展开测试时间已经不够。对此我们做了如下处理：

<ol>
<li>前后端分别生成mock数据进行单元测试。因为即使在测试环境的数据库里生成测试数据也是一件很复杂的工作，所以我们可以用mock数据检查各种复杂场景。这样在联调通过后对系统进行集成测试只要选取少数典型场景进行测试就可以了，大大减少了测试工作量。而且对于后端，可以直接在开发的项目里编写Java单元测试脚本，每次可以自动回归。</li>
<li>坐在一起工作。发现问题提交到bug系统后不要等待对方回复然后修复，直接抓人当面交流。如果已经清楚bug原因和修复方案的话，直接修改然后拉对方做代码评审是效率最高的做法。</li>
<li>对于上下游组件的测试，一定要约定好数据交换格式和接口。因为是o2o活动，我们输入的影院数据要经过引擎的处理展现给附近页面，但是这个流程连续三天没有走通，最好发现是数据格式约定有问题，有一个字段引擎默认我们会正确设定所以没有告知，而实际上我们根本不知道这个字段的作用。这个教训值得深刻总结。</li>
</ol>
</li>
<li>对于抢购／秒杀类的活动，一定要注意以下两个问题：

<ol>
<li>性能测试。在第一次性能测试的时候我们发现了缓存没有被正确使用，导致预定的性能指标远远不能达到。</li>
<li>潜在的死锁问题。在一个被精心构造的场景里，我们发现当所有座位被选，即使因为有人因为15分钟内为付款导致座位被释放，其他人也无法进入选座页面选择被释放的座位。后来经过排查，是判断座位释放和更新座位状态的代码逻辑有问题。如果等活动发生时再注意到这个问题，那么很多座位会因为这个原因导致无法被售出。</li>
</ol>
</li>
<li>O2O活动的offline要非常重视，为了保证线下核销能正常进行，我们专门组织了影院实地测试，发现了一系列原来没有充分考虑的问题：

<ol>
<li>影院不认短信核销，必须检查淘宝的卡券包。</li>
<li>现场没有wifi，而且有些影院2G/3G信号不大好，部分影院完全没有信号。</li>
<li>卡券包没有做本地缓存，弱网络情况下花了至少5分钟才打开。考虑活动当天影院淘宝全部包场，如果核销速度慢的话肯定会影响入场进度。</li>
<li>给影院的培训资料全是基于iOS版淘宝的，有些服务员不会使用Android版的客户端。</li>
</ol>
</li>
<li>自动化工具很重要。当天共有超过200家影院超过7000场电影需要排期，运营和影院交流后给出了一套复杂的规则，但是如果人肉做的话至少2人天的工作量，测试在了解需求后主动为运营编写的一个自动排期脚本，几秒钟就能完成排期并生成数据订正脚本。</li>
<li>线下数据靠不住。影院方提供的数据不能100%相信，经常会出现一些莫名其妙的问题。比如座位给多了，场次排重了等。必须根据已有的数据及时核对并反馈。</li>
<li>敏捷！前线的需求就是我们的任务，凌晨2点下班不算太晚，即使在活动最后一天还是有各种突发状况，比如某个影院突然停电，我们必须赶快安排退票补偿事宜。</li>
</ol>


<h3>效果怎么样？</h3>

<p>不谈最后结果的分享都是耍流氓！关于效果吗，参考淘宝官方公布的数字！而且由于对线下测试及时的发现了各类问题，最后3月8号活动当天，核销进展顺利。客服的妹子们只接到了少数几个咨询电话。</p>
]]></content>
  </entry>
  
</feed>
